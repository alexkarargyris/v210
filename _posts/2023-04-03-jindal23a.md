---
title: Contrastive Representation Learning for Gaze Estimation
abstract: Self-supervised learning (SSL) has become prevalent for learning representations
  in computer vision. Notably, SSL exploits contrastive learning to encourage visual
  represen- tations to be invariant under various image transformations. The task
  of gaze estimation, on the other hand, demands not just invariance to various appearances
  but also equiv- ariance to the geometric transformations. In this work, we propose
  a simple contrastive representation learning framework for gaze estimation, named
  Gaze Contrastive Learning (GazeCLR). GazeCLR exploits multi-view data to promote
  equivariance and relies on selected data augmentation techniques that do not alter
  gaze directions for invariance learning. Our experiments demonstrate the effectiveness
  of GazeCLR for several settings of the gaze estimation task. Particularly, our results
  show that GazeCLR improves the performance of cross-domain gaze estimation and yields
  as high as 17.2% relative improve- ment. Moreover, the GazeCLR framework is competitive
  with state-of-the-art representation learning methods for few-shot evaluation. The
  code and pre-trained models are available at https://github.com/jswati31/gazeclr.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jindal23a
month: 0
tex_title: Contrastive Representation Learning for Gaze Estimation
firstpage: 37
lastpage: 49
page: 37-49
order: 37
cycles: false
bibtex_author: Jindal, Swati and Manduchi, Roberto
author:
- given: Swati
  family: Jindal
- given: Roberto
  family: Manduchi
date: 2023-04-03
address:
container-title: Proceedings of The 1st Gaze Meets ML workshop
volume: '210'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 3
pdf: https://proceedings.mlr.press/v210/jindal23a/jindal23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
